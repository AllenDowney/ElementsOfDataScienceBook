\hypertarget{preface}{%
\chapter{Preface}\label{preface}}

\emph{Elements of Data Science} is an introduction to data science for
people with no programming experience. My goal is to present a small,
powerful subset of Python that allows you to do real work in data
science as quickly as possible.

I don't assume that the reader knows anything about programming,
statistics, or data science. And I don't use much math other than
arithmetic and logarithms.

The chapters of this book are available in Jupyter notebooks where you
can run the code and work on the exercises. You can download the
notebooks and run them on your own computer, or if you don't want to
install anything, you can run them on Google Colab.

\hypertarget{topics}{%
\section{Topics}\label{topics}}

This book is organized in three parts followed by two case studies.

\textbf{From Python to Pandas:} The first part includes six chapters
that introduce lists, dictionaries, NumPy arrays and Pandas DataFrames;
data types including integers, floating-point numbers, times and dates,
latitude and longitude, strings, and text files; and line and bar plots.

\textbf{Exploratory Data Analysis:} Four chapters that introduce data
cleaning and validation; visualization of distributions with histograms,
discrete PMFs and CDFs, and kernel density estimation (KDE);
visualization of relationships using scatter plots, box plots, and
violin plots; and quantification of relationships using correlation and
regression (simple, multiple, and logistic). Examples use data from a
variety of sources, including the National Survey of Family Growth
(NSFG) and the Behavior Risk Factor Surveillance Survey (BRFSS).

\textbf{Computational Inference:} Three chapters that use resampling,
bootstrapping, and permutation to introduce statistical inference.
Examples use data from the NSFG and BRFSS again, and from the General
Social Survey (GSS).

\textbf{Political Alignment Case Study:} Using data from the GSS again,
we introduce cross tabulation, pivot tables, and the Pandas group-by
operation. Readers use these tools to explore changing opinions on a
variety of topics among survey respondents in the United States.

\textbf{Recidivism Case Study:} This case study is based on a well-known
article, ``Machine Bias'', which was published by Politico in 2016. It
relates to COMPAS, a statistical tool used in the criminal justice
system to assess the risk that a defendant will commit another crime if
released. The ProPublica article concludes that COMPAS is unfair to
Black defendants because they are more likely to be misclassified as
high risk. A response article in the Washington Post suggests that
``It's actually not that clear.'' Using the data from the original
article, this case study defines the metrics used to evaluate binary
classifiers, explains the challenges of defining algorithmic fairness,
and provides an engaging starting place for discussions of the context,
ethics, and social impact of data science.

\hypertarget{working-with-the-code}{%
\section{Working with the Code}\label{working-with-the-code}}

The easiest way to work with the code in this book is to run the
notebooks on Colab, which is a free Jupyter environment that runs on
Google servers. You can get to the notebooks from the landing page for
this book at \url{https://allendowney.github.io/ElementsOfDataScience}.

If you would rather run the notebooks on your own computer, there are
two steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Download the notebooks in a Zip file from \textless\textgreater.
\item
  Install Jupyter, Python, and the Python libraries the notebooks depend
  on.
\end{enumerate}

